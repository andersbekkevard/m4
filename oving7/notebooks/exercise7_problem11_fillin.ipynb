{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 4N / 4D: Bias of explicit and implicit Euler\n",
    "\n",
    "Experiment for $y' = y^2,\\ y(0)=1$\n",
    "\n",
    "This notebook compares forward Euler and backward Euler and shows the sign bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Consider the scalar autonomous initial value problem\n",
    "$$\n",
    "y'(t) = f(y(t)), \\qquad y(0)=y_0,\n",
    "$$\n",
    "with $f\\in C^2$ on a neighbourhood of $y_0$ and let $y_{\\text{E}} := y_0 + h f(y_0)$ and $y_{\\text{I}} := y_0 + h f(y_{\\text{I}})$ be the point obtained by using the explicit or implicit Euler method for one step with some step size $h$.\n",
    "***\n",
    "b) Consider the test problem\n",
    "$$\n",
    "y'(t) = y(t)^2,\\qquad y(0)=1,\n",
    "$$\n",
    "whose exact solution is $y(t) = 1/(1-t)$ (blow-up at $t=1$). Note that $f(y)=y^2$ is convex and $f(1)=1>0$. Implement both forward (explicit) Euler and backward (implicit) Euler and compare them with the exact solution on $t\\in[0,0.6]$ for several step sizes $h$ (e.g. $h=0.1,\\ 0.05,\\ 0.02,\\ 0.01$):\n",
    "1. plot numerical and exact solutions,\n",
    "1. tabulate the error $E(h)=|y_N-y(T)|$ at $T=0.6$,\n",
    "1. comment whether the observed bias matches the Taylor-based prediction.\n",
    "\n",
    "Repeat the experiment for a negative initial value, $y(0)=-1$, so $f(y)=y^2>0$ still; comment on the bias.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the TODOs and run the experiments.\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(y):\n",
    "    # right-hand side\n",
    "    return y**2\n",
    "\n",
    "def y_exact(t):\n",
    "    # exact solution for y' = y^2 with y(0)=1\n",
    "    return 1.0 / (1.0 - t)\n",
    "\n",
    "def forward_euler_step(y, h):\n",
    "    return y + h * f(y)\n",
    "\n",
    "# TODO: implement backward Euler step (solve quadratic)\n",
    "def backward_euler_step(y, h):\n",
    "    # solve h*y_next^2 - y_next + y = 0\n",
    "    # use quadratic formula for exact computation and no iterative solver\n",
    "    # TODO: choose correct root - (explain why you choose it)\n",
    "    return \n",
    "\n",
    "# %%\n",
    "# TODO: choose step sizes and T\n",
    "T = 0.6\n",
    "steps = [0.1, 0.05, 0.02, 0.01]\n",
    "\n",
    "def get_results(y0, T, steps):\n",
    "\tresults = []\n",
    "\tfor h in steps:\n",
    "\t\tN = int((T+1e-12) / h) # number of steps, add small tolerance to avoid rounding issues\n",
    "\t\tt = np.linspace(0, N*h, N+1)\n",
    "\t\t# forward Euler\n",
    "\t\ty_f = np.zeros(N+1)\n",
    "\t\ty_f[0] = y0\n",
    "\t\tfor n in range(N):\n",
    "\t\t\ty_f[n+1] = forward_euler_step(y_f[n], h)\n",
    "\t\t# backward Euler\n",
    "\t\ty_b = np.zeros(N+1)\n",
    "\t\ty_b[0] = y0\n",
    "\t\tfor n in range(N):\n",
    "\t\t\ty_b[n+1] = backward_euler_step(y_b[n], h)\n",
    "\t\t# exact at final time\n",
    "\t\tyT = y_exact(t[-1], y0=y0)\n",
    "\t\terr_f = y_f[-1] - yT\n",
    "\t\terr_b = y_b[-1] - yT\n",
    "\t\tresults.append((h, t, y_f, y_b, yT, err_f, err_b))\n",
    "\treturn results\n",
    "\n",
    "results = get_results(y0=y0, T=T, steps=steps)\n",
    "\n",
    "# %%\n",
    "# Plot one representative case, say h=0.05\n",
    "for i in range(len(results)):\n",
    "    h, t, y_f, y_b, yT, err_f, err_b = results[i]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(t, y_f, 'o-', label=f'Forward Euler h={h}')\n",
    "    plt.plot(t, y_b, 's--', label=f'Backward Euler h={h}')\n",
    "    t_exact = np.linspace(0, T, 201)\n",
    "    plt.plot(t_exact, y_exact(t_exact), 'k-', label='Exact')\n",
    "    plt.ylim(0, max( max(y_f), max(y_b), max(y_exact(t_exact)) )*1.1)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('y(t)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "# Print error table\n",
    "table = pd.DataFrame(columns=['h', 'Forward-last', 'Forward Error', 'Backward-last', 'Backward Error', 'Exact'])\n",
    "for i in range(len(results)):\n",
    "\tresi = results[i]\n",
    "\ttable.loc[i] = [resi[0],resi[2][-1],resi[5],resi[3][-1],resi[6],resi[4]]\n",
    "display(table)\n",
    "\n",
    "# %%\n",
    "# TODO: Answer the guided questions in a short text cell:\n",
    "# - Do explicit and implicit show under/overestimation?\n",
    "# - Does it agree with the Taylor-based prediction?\n",
    "# - Try y(0) = -1 and comment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "d) Implement the following methods and run them on our test problem:\n",
    "1. Forward Euler (explicit, order 1),\n",
    "1. Explicit midpoint (order 2),\n",
    "1. Heun's method (explicit RK2 / improved Euler, order 2),\n",
    "1. Backward Euler (implicit, order 1),\n",
    "1. Trapezoidal rule (implicit, order 2).\n",
    "\n",
    "For each method and compute the final error $E(h)=y(T)-y_N$ (signed error) and report whether the method over- or underestimates the exact value. Compare observations with the theoretical sign of the leading bias from (2).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
